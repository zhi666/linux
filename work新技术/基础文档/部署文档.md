[TOC]

# Master模板机 Docker版本部署文档

### docker

```
echo "net.ipv4.ip_forward = 1" >> /etc/sysctl.conf 
sysctl -p 

yum install -y yum-utils   device-mapper-persistent-data   lvm2

yum-config-manager     --add-repo     https://download.docker.com/linux/centos/docker-ce.repo

yum install -y  docker-ce docker-ce-cli containerd.io

systemctl start docker &&  systemctl enable docker


yum install -y bash-completion
source /usr/share/bash-completion/completions/docker
source /usr/share/bash-completion/bash_completion
```



## Zabbix及Jumpserver所需数据库部署

```

mkdir /data/dzzoffice -p
mkdir /data/mysql/data/ -p

```



### Mysql

```bash
docker run --name mysql -t \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -p 3368:3306 \
      -e MYSQL_DATABASE="zabbix" \
      -e MYSQL_USER="zabbix" \
      -e MYSQL_PASSWORD="zabbix_pwd" \
      -e MYSQL_DATABASE="jumpserver" \
      -e MYSQL_ROOT_PASSWORD="root_Password@" \
      -v /data/mysql/data:/var/lib/mysql \
      -d mysql:5.7.28 \
      --character-set-server=utf8 --collation-server=utf8_bin
```

### Redis

```bash
docker run --name redis -t \
      --hostname redis \
      --restart=always \
      -v /etc/localtime:/etc/localtime:ro \
      -v /data/redis/data:/data \
      -d redis:alpine
```

## 协同办公平台

### dzzoffice

```bash
docker run -d --name dzzoffice -p 9300:80 --restart=always -v /data/dzzoffice/data:/var/www/html/data imdevops/dzzoffice:latest


wget https://github.com/zyx0814/dzzoffice/archive/2.02.tar.gz
解压包，然后把里面的dzzoffice-2.02目录下的包复制到/data/dzzoffice/data下面，然后是所有权限，
chmod 777 data -R

http://192.168.224.11:9300/install/index.php  输入网址安装。
数据库地址填写容器的地址。
```



### onlyoffice

```
docker run -it -d  --name onlyoffice -p8000:80 --restart=always onlyoffice/documentserver

然后在dzzoffice中进行配置：

管理 -》 应用市场 -》 在应用市场内找到 “onlyoffice” 应用 点击 一键安装

管理 -》 应用市场 -》 已安装 中 点击设置按钮 进入设置页面

这里填写您的文档服务器的地址：如文档服务器地址为 http://192.168.224.11， 文档服务器端口为：8000
那么 这里的地址应该是：
http://192.168.224.11:8000/web-apps/apps/api/documents/api.js
然后进入应用市场，把相关的都下载好，并启用。


```



## 接口文档平台

### showdoc

```bash
docker run -d --name showdoc -p 4999:80 -v /data/showdoc_data/html:/var/www/html/ star7th/showdoc
```

## Zabbix Server部署

### zabbix-java-gateway

```bash
docker run --name zabbix-java-gateway -t \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -d zabbix/zabbix-java-gateway:latest
```

### zabbix-snmptraps

```bash
docker run --name zabbix-snmptraps -t \
      -v /zbx_instance/snmptraps:/var/lib/zabbix/snmptraps:rw \
      -v /var/lib/zabbix/mibs:/usr/share/snmp/mibs:ro \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -p 162:162/udp \
      -d zabbix/zabbix-snmptraps:latest
```

### zabbix-server-mysql

```bash
docker run --name zabbix-server-mysql -t \
      -e DB_SERVER_HOST="mysql" \
      -e MYSQL_DATABASE="zabbix" \
      -e MYSQL_USER="zabbix" \
      -e MYSQL_PASSWORD="zabbix_pwd" \
      -e MYSQL_ROOT_PASSWORD="root_Password@" \
      -e ZBX_JAVAGATEWAY="zabbix-java-gateway" \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -e PHP_TZ="Asia/Shanghai" \
      --volumes-from zabbix-snmptraps \
      --link mysql:mysql \
      --link zabbix-java-gateway:zabbix-java-gateway \
      -p 10051:10051 \
      -d zabbix/zabbix-server-mysql:latest
```

### zabbix-web-nginx-mysql

```bash
docker run --name zabbix-web-nginx-mysql -t \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -e DB_SERVER_HOST="mysql" \
      -e MYSQL_DATABASE="zabbix" \
      -e MYSQL_USER="zabbix" \
      -e MYSQL_PASSWORD="zabbix_pwd" \
      -e MYSQL_ROOT_PASSWORD="root_Password@" \
      -e PHP_TZ="Asia/Shanghai" \
      --link mysql:mysql \
      --link zabbix-server-mysql:zabbix-server \
      -p 8080:8080 \
      -d zabbix/zabbix-web-nginx-mysql:latest
      
 登录web
 用户 Admin
 密码 zabbix
```



## Grafana 部署

```bash
docker run --name grafana -t \
      --hostname grafana \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -e "GF_INSTALL_PLUGINS=alexanderzobnin-zabbix-app,raintank-worldping-app,grafana-piechart-panel,grafana-clock-panel,farski-blendstat-panel" \
      -v /data/grafana:/var/lib/grafana \
      -p 3000:3000 \
      -d grafana/grafana
      
登录web 
默认用户 admin 密码 admin

```

## JumpServer部署

###  core

```bash
docker run --name jms_core2 -t \
      --hostname jms_core2 \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -e SECRET_KEY="wqeJWlcNmQfpfr7ZFXuT2h8v5O5BYxNuq733hNedIrOVzDorNe" \
      -e BOOTSTRAP_TOKEN="Uy9LKHC4KGIY7QMA" \
      -e DB_ENGINE="mysql" \
      -e DB_HOST=mysqld \
      -e DB_PORT="3306" \
      -e DB_USER="root" \
      -e DB_PASSWORD="root_Password@" \
      -e DB_NAME="jumpserver" \
      -e REDIS_HOST=redis \
      -e REDIS_PORT=6379 \
      --link mysql:mysqld \
      --link redis:redis \
      -v /data/jumpserver/core/data/static:/opt/jumpserver/data/static \
      -v /data/jumpserver/core/data/media:/opt/jumpserver/data/media \
      -v /data/jumpserver/core/logs:/opt/jumpserver/logs \
      -d wojiushixiaobai/jms_core:2.0.1
```

###  koko

```bash
docker run --name jms_koko2 -t \
      --hostname jms_koko2 \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -e CORE_HOST="http://core:8080" \
      -e BOOTSTRAP_TOKEN="Uy9LKHC4KGIY7QMA" \
      -p 2020:2222 \
      --link jms_core:core \
      -v /data/jumpserver/koko/data/keys:/opt/koko/data/keys \
      -d wojiushixiaobai/jms_koko:2.0.1
```

###   guacamole

```bash
docker run --name jms_guacamole2 -t \
      --hostname jms_guacamole2 \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      -e JUMPSERVER_SERVER="http://core:8080" \
      -e BOOTSTRAP_TOKEN="Uy9LKHC4KGIY7QMA" \
      -e JUMPSERVER_KEY_DIR="/config/guacamole/keys" \
      -e GUACAMOLE_HOME="/config/guacamole" \
      -e GUACAMOLE_LOG_LEVEL="ERROR" \
      --link jms_core2:core \
      -v /data/jumpserver/guacamole/keys:/config/guacamole/keys \
      -d wojiushixiaobai/jms_guacamole:2.0.1
```

###  nginx

```bash
docker run --name jms_nginx2 -t \
      --hostname jms_nginx2 \
      --restart=always \
      -v /etc/localtime:/etc/localtime \
      --link jms_core2:core \
      --link mysql:mysql \
      --link redis:redis \
      --link jms_koko2:koko \
      --link jms_guacamole2:guacamole \
      -p 88:80 \
      -v /data/jumpserver/core/data:/opt/jumpserver/data \
      -d jumpserver/jms_nginx:2.0.1

```

**注：当前未用此种方式部署jumpserver  采用自编译dockerfile方式**

### Git

```
gitlab-runner register \
  --non-interactive \
  --url "https://gitlab.com/" \ # 填入对应url
  --registration-token "PROJECT_REGISTRATION_TOKEN" \ # 填入对应token
  --executor "docker" \
  --docker-image alpine:latest \ # runner的docker基础镜像
  --description "docker-runner" \
  --tag-list "docker,aws" \
  --run-untagged="true" \
  --locked="false" \
  --access-level="not_protected"
```

### 容器自动更新

```
docker run -d \
    --name watchtower \
    --restart unless-stopped \
    -v /var/run/docker.sock:/var/run/docker.sock \
    containrrr/watchtower -c \
    $(cat ~/容器自动更新白名单.txt)
```

容器自动更新白名单.txt

```
angry_elgamal
watchtower
zabbix-java-gateway
zabbix-snmptraps
zabbix-server-mysql
zabbix-web-nginx-mysql
grafana
gitlab-ce
gitlab-runner

```





## Elk+filebeat+kafka

### docker volume 持久化插件

```bash
vim /etc/systemd/system/docker-volume-local-persist.service
#文件内容为
[Unit]
Description=docker-volume-local-persist
Before=docker.service
Wants=docker.service

[Service]
TimeoutStartSec=0
ExecStart=/usr/bin/docker-volume-local-persist

[Install]
WantedBy=multi-user.target

```

```bash
wget https://github.com/MatchbookLab/local-persist/releases/download/v1.3.0/local-persist-linux-amd64
 
chmod +x local-persist-linux-amd64  && mv local-persist-linux-amd64 docker-volume-local-persist && mv docker-volume-local-persist /usr/bin/

systemctl daemon-reload && systemctl enable docker-volume-local-persist && systemctl start docker-volume-local-persist

```





### 安装所需组件

/etc/sysct.conf新增两条

```bash
net.ipv4.ip_forward = 1
vm.max_map_count=262144
#运行命令
sysctl -p --system
```



```bash
mkdir -p /elk/logstash

mv logstash-kafka.conf /elk/logstash
```



logstash-kafka.conf 文件内容为

```yaml
input {
#    # 来源beats
#    beats {
        # 端口
#        port => "5044"
#    }
  kafka {
    bootstrap_servers => "kafka1:9092"
    topics => ["all_logs"]
    group_id => "logstash"
    codec => json
  }

}
# 分析、过滤插件，可以多个
filter {
#    grok {
#        match => { "message" => "%{COMBINEDAPACHELOG}"}
#    }
#    geoip {
#        source => "clientip"
#    }
}
output {
    # 选择elasticsearch
    elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        #index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
        index => "all-logs-%{+YYYY.MM.dd}"
        user => "elastic"
        password => "secret"

    }
}

```



 ```bash
mkdir -p /root/elk
mv docker-compose.yml /root/elk &&  cd /root/elk && docker-compose up -d
 ```

docker-compose.yml文件内容为

```yaml
version: '3'
services:
  elasticsearch:
    restart: always
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.4.2
    environment:
      - discovery.type=single-node
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch:/usr/share/elasticsearch/data:rw
      - /etc/localtime:/etc/localtime
    networks:
      - elastic

  kibana:
    image: docker.elastic.co/kibana/kibana:7.4.2
    restart: always
    container_name: kibana
    volumes:
      - kibana:/usr/share/kibana/config:rw
      - /etc/localtime:/etc/localtime
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    environment:
      SERVER_NAME: kibana.example.org
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    networks:
      - elastic


  logstash:
    image: docker.elastic.co/logstash/logstash:7.4.2
    container_name: logstach
    command: logstash -f /usr/share/logstash/conf/logstash-kafka.conf
    restart: always
    tty: true 
    ports:
      - "5044:5044"
    volumes:
      - /etc/localtime:/etc/localtime
      - logstash:/usr/share/logstash/conf/logstash-kafka.conf
    environment:
      - elasticsearch.hosts=http://elasticsearch:9200
      - xpack.monitoring.elasticsearch.hosts=http://elasticsearch:9200
    networks:
      - elastic
    links:
      - kafka1
      - zookeeper
    depends_on:
      - elasticsearch

  zookeeper:
    restart: always
    image: zookeeper:3.5.5
    restart: always
    container_name: zookeeper
    volumes:
      - /etc/localtime:/etc/localtime
      - zookeeper:/data
      - zookeeper1:/datalog
    networks:
      - elastic
    ports:
      - "2181:2181"
  kafka1:
    container_name: kafka1
    image: wurstmeister/kafka
    depends_on:
      - zookeeper
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - kafka:/kafka
      - /etc/localtime:/etc/localtime
    links:
      - zookeeper
    ports:
      - "9092:9092"
    networks:
      - elastic
    environment:
      - KAFKA_LISTENERS=PLAINTEXT://kafka1:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:9092
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_MESSAGE_MAX_BYTES=2000000
      - KAFKA_CREATE_TOPICS=all_logs:1:1

volumes:
  elasticsearch:
    driver: local-persist
    driver_opts:
      mountpoint: /elk/elasticsearch/
  kibana:
    driver: local-persist
    driver_opts:
      mountpoint: /elk/kibana/
  logstash:
    driver: local-persist
    driver_opts:
      mountpoint: /elk/logstash/
  zookeeper:
    driver: local-persist
    driver_opts:
      mountpoint: /elk/zookeeper/data/
  zookeeper1:
    driver: local-persist
    driver_opts:
      mountpoint: /elk/zookeeper/datalog/
  kafka:
    driver: local-persist
    driver_opts:
      mountpoint: /elk/kafka/

networks:
  elastic:
    driver: bridge


```

**filebeat 客户端安装方式**

```bash
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.4.2-linux-x86_64.tar.gz

tar xzvf filebeat-7.4.2-linux-x86_64.tar.gz
cd filebeat-7.4.2-linux-x86_64

```

修改filebeat.yml文件内容

内容为

```yaml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/nginx/*.log


filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: false

setup.template.settings:
  index.number_of_shards: 1

setup.dashboards.enabled: false

setup.kibana:
  host: "http://kafka1:5601"
output.kafka:
    hosts: ["kafka1:9092"]
    topic: 'all_logs'
    codec.json:
      pretty: false

```

**注意 客户端hosts 添加 kafka1 对应server的ip地址  以及filebeat 配置建议使用ansible**

```bash
#客户端启动服务
./filebeat &
```

